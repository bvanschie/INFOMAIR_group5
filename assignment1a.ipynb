{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ass1a\n",
    "In this assignment we implement two baseline and two more advanced machine learning models for classifying dialog acts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import sklearn.tree as sk_tree\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "import torch\n",
    "from torch.nn import Module, Linear, ReLU, Sequential, Sigmoid, Dropout\n",
    "from torch.nn.functional import cross_entropy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "First we define some utility functions to load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Loads the data file from the provided path.\n",
    "    Returns a tuple of numpy arrays, each with shape (N,) where N is\n",
    "    the batch size. The first element contains a list of utterances, the\n",
    "    second element contains the corresponding labels (as string).\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    data = list(map(lambda s: [s.split()[0].lower(), ' '.join(s.split()[1:]).lower()], lines))\n",
    "    data = np.array(data).T\n",
    "    return data[1], data[0]\n",
    "\n",
    "\n",
    "def preprocess_data(text: np.ndarray, vectorizer: CountVectorizer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts an array of strings into their bag of words representation\n",
    "    using the provided vectorizer.\n",
    "    :param text: np array of strings of shape (B,)\n",
    "    :param vectorizer: The vectorizer to use.\n",
    "    :return: A numpy array of shape (B, W) where B is the batch size (number of input strings)\n",
    "    and W is the number of words used by the vectorizer in the bag of words prepresentation.\n",
    "    \"\"\"\n",
    "    out = vectorizer.transform(text)\n",
    "    out = np.array(out.toarray())\n",
    "    return out\n",
    "\n",
    "\n",
    "def preprocess_labels(labels: np.ndarray, mapping: np.ndarray):\n",
    "    \"\"\"\n",
    "    Converts an array labels (string) into a numpy array of the\n",
    "    corresponding class indices.\n",
    "    :param labels: The list of string labels.\n",
    "    :param mapping: An array containing all the labels. This list will\n",
    "    be used as basis to determining the labels index.\n",
    "    Eg.: if mapping = ['label1', 'label2', 'label3'] then\n",
    "    all entries of 'labels' containing label1 will be mapped to 0, \n",
    "    label2 to 1, and label3 to 2.\n",
    "    :return: A numpy array with the index of labels.\n",
    "    \"\"\"\n",
    "    out = [mapping.tolist().index(l) for l in labels]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load in the data and split it into training and testing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_data(\"data/dialog_acts.dat\")\n",
    "\n",
    "# The ratio of training data.\n",
    "split = .85\n",
    "\n",
    "split = int(split * data.shape[0])\n",
    "training_data = data[:split]\n",
    "training_labels = labels[:split]\n",
    "test_data = data[split:]\n",
    "test_labels = labels[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtain a list of all labels that are used in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels in this dataset are: ['ack' 'affirm' 'bye' 'confirm' 'deny' 'hello' 'inform' 'negate' 'null'\n",
      " 'repeat' 'reqalts' 'reqmore' 'request' 'restart' 'thankyou']\n"
     ]
    }
   ],
   "source": [
    "LABELS = np.unique(labels)\n",
    "print(f\"The labels in this dataset are: {LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining baseline classifiers\n",
    "Now we can start defining our classifiers. The first one is going to be the majority classifier. All models will have the general interface of a \\_\\_call\\_\\_ method that takes an array of strings as input, and outputs an array of integers each corresponding to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityClassifier:\n",
    "    \"\"\"\n",
    "    This classifier always returns the label for the majority class.\n",
    "    \"\"\"\n",
    "    def __init__(self, return_value: int):\n",
    "        \"\"\"\n",
    "        Init.\n",
    "        :param return_value: The value to return. Should be the\n",
    "        index of the majority class in the dataset.\n",
    "        \"\"\"\n",
    "        self.return_value = return_value\n",
    "\n",
    "    def __call__(self, texts: np.ndarray) -> np.ndarray:\n",
    "        return np.full(shape=texts.shape, fill_value=self.return_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keyword classifier reads in a json file containing all the label names and their corresponding keywords. It will then top to bottom check all possibilities, and return the label of the first match. If no match found 'null' is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordClassifier:\n",
    "    \"\"\"\n",
    "    This classifier uses a keyword list to determine the\n",
    "    dialog act of an utterance.\n",
    "    \"\"\"\n",
    "    def __init__(self, keyword_dict: str):\n",
    "        \"\"\"\n",
    "        Init.\n",
    "        :param keyword_dict: Path to the file containing the keywords for\n",
    "        the different labels.\n",
    "        \"\"\"\n",
    "        with open(keyword_dict, 'r') as file:\n",
    "            self.keywords = json.load(file)\n",
    "        self.label_names = LABELS.tolist()\n",
    "\n",
    "    def __call__(self, texts: np.ndarray) -> np.ndarray:\n",
    "        def find_keyword(s):\n",
    "            \"\"\"\n",
    "            Finds the first label such that the text contains a word\n",
    "            in the list of the label's keywords.\n",
    "            :param s: The text to find the keyword in.\n",
    "            :return: The first matching label.\n",
    "            \"\"\"\n",
    "            for k, _ in self.keywords.items():\n",
    "                if any([w in s.split() for w in self.keywords[k]]):\n",
    "                    return k\n",
    "            # If no keyword is matched return null.\n",
    "            return 'null'\n",
    "\n",
    "        predictions = [find_keyword(s) for s in texts]\n",
    "        return np.array([self.label_names.index(p) for p in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, vectorizer: CountVectorizer, tfidf, max_depth: Union[int, None] = None):\n",
    "        \"\"\"\n",
    "        Init.\n",
    "        :param vectorizer: The vectorizer to use when converting the string input\n",
    "        into bag of words representation.\n",
    "        :param max_depth: The maximum depth of the tree.\n",
    "        \"\"\"\n",
    "        self.vectorizer = vectorizer\n",
    "        self.tfidf = tfidf\n",
    "        self.clf = sk_tree.DecisionTreeClassifier(max_depth=max_depth)\n",
    "\n",
    "    def __call__(self, texts: np.ndarray):\n",
    "        vec = self.tfidf.transform(self.vectorizer.transform(texts))\n",
    "        vec = np.array(vec.toarray())\n",
    "        out = self.clf.predict(vec)\n",
    "        return out\n",
    "    \n",
    "    def fit(self, x, y, sample_weights):\n",
    "        \"\"\"\n",
    "        Fits the tree.\n",
    "        :param x: The data to fit on.\n",
    "        :param y: The labels of the data.\n",
    "        :param sample_weights: The sample weights to use in case\n",
    "        of imbalanced classes.\n",
    "        \"\"\"\n",
    "        x = preprocess_data(x, self.vectorizer)\n",
    "        y = preprocess_labels(y, mapping=LABELS)\n",
    "        self.clf.fit(x, y, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model is a simple 2 layer feed-forward neural network implemented in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkClassifier(Module):\n",
    "    def __init__(self, vectorizer: CountVectorizer, tfidf, hidden_size: int):\n",
    "        \"\"\"\n",
    "        Init.\n",
    "        :param vectorizer: The vectorizer to use when converting the string input\n",
    "        into bag of words representation.\n",
    "        :param max_depth: The maximum depth of the tree.\n",
    "        \"\"\"\n",
    "        super(NeuralNetworkClassifier, self).__init__()\n",
    "        dim = vectorizer.transform(['x']).toarray().shape[1]\n",
    "        self.net = Sequential(\n",
    "            Linear(in_features=dim, out_features=512),\n",
    "            ReLU(),\n",
    "            Dropout(0.2),\n",
    "            Linear(in_features=512, out_features=256),\n",
    "            ReLU(),\n",
    "            Dropout(0.2),\n",
    "            Linear(in_features=256, out_features=len(LABELS))\n",
    "        )\n",
    "        self.vectorizer = vectorizer\n",
    "        self.tfidf = tfidf\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        vec = self.tfidf.transform(self.vectorizer.transform(x))\n",
    "        vec = torch.tensor(vec.toarray(), dtype=torch.float32)\n",
    "        return self.net(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating classifiers\n",
    "### Helper functions\n",
    "Since most of the models have a similar interface, it is a good idea to make a single function that can be used to evaluate multiple instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(classifier, data: np.ndarray, labels: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Evaluates the classifier on the given batch. Outputs the accuracy and the confusion matrix.\n",
    "    :param classifier: The classifier to evaluate.\n",
    "    :param data: The test data.\n",
    "    :param labels: Test labels.\n",
    "    :return: A tuple of (accuracy, confusion matrix).\n",
    "    \"\"\"\n",
    "    # If the classifier is a torch module the input type should be a tensor\n",
    "    # and not a numpy array.\n",
    "    if isinstance(classifier, Module):\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    pred = classifier(data)\n",
    "    labels = preprocess_labels(labels, mapping=LABELS)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    conf_mat = confusion_matrix(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return acc, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will work for 3 out of 4 models, but not for the neural network as it needs special treatment regarding gradients. So we define another test function specifically for pytorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(network: Module, data: np.ndarray, labels: np.ndarray)-> Tuple[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Evaluates the network on the dataset.\n",
    "    :param network: pytorch Module.\n",
    "    :param data: Array of string utterances.\n",
    "    :param labels: Array of string labels.\n",
    "    :return: A tuple of (accuracy, confusion matrix).\n",
    "    \"\"\"\n",
    "    network.train(False)\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(network(data), dim=1, keepdim=False).numpy()\n",
    "    labels = preprocess_labels(labels, mapping=LABELS)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    conf_mat = confusion_matrix(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return acc, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network also needs to be trained, so we define a training loop as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(network: Module, optimizer, data: np.ndarray, labels: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Trains the network.\n",
    "    :param netowrk: pytorch Module to train.\n",
    "    :param optimizer: The optimizer to use for training.\n",
    "    :param data: Array of string utterances.\n",
    "    :param labels: Array of string labels.\n",
    "    \"\"\"\n",
    "    network.train(True)\n",
    "    target = torch.tensor(preprocess_labels(labels, mapping=LABELS), dtype=torch.long)\n",
    "    out = network(data)\n",
    "    # Class weight is the inverse of frequency.\n",
    "    sample_weights = np.unique(labels, return_counts=True)[1]\n",
    "    sample_weights = 1 / sample_weights\n",
    "    loss = cross_entropy(input=out, target=target, weight=torch.tensor(sample_weights, dtype=torch.float32))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the models\n",
    "Now we will evaluate the models, starting with the majority classifier. The return value will be the index of the label 'inform' as it is the dominant class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of majority classifier: 37.611%\n"
     ]
    }
   ],
   "source": [
    "majority_c = MajorityClassifier(return_value=LABELS.tolist().index('inform'))\n",
    "acc, _ = test_classifier(classifier=majority_c, data=test_data, labels=test_labels)\n",
    "print(f\"Accuracy of majority classifier: {acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the keyword classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of keyword classifier: 25.614%\n"
     ]
    }
   ],
   "source": [
    "keyword_c = KeywordClassifier(\"data/kw.json\")\n",
    "acc, _ = test_classifier(classifier=keyword_c, data=test_data, labels=test_labels)\n",
    "print(f\"Accuracy of keyword classifier: {acc * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the advanced models we need to setup a vectorizer first, that converts the strings to bag of words vectors. It is fit on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "_ = tfidf.fit_transform(vectorizer.fit_transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and evaluating a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decision tree classifier.\n",
      "Decision tree trained. Accuracy on training set: 63.251%\n"
     ]
    }
   ],
   "source": [
    "decision_tree_c = DecisionTreeClassifier(vectorizer, tfidf, max_depth=30)\n",
    "\n",
    "print(\"Training decision tree classifier.\")\n",
    "\n",
    "sample_weights = np.unique(training_labels, return_counts=True)[1]\n",
    "sample_weights = 1 / sample_weights\n",
    "sample_weights = list(zip(range(0, len(sample_weights)), sample_weights))\n",
    "sample_weights = compute_sample_weight(dict(sample_weights), preprocess_labels(training_labels, mapping=LABELS))\n",
    "\n",
    "decision_tree_c.fit(training_data, training_labels, sample_weights)\n",
    "acc, conf_mat = test_classifier(decision_tree_c, test_data, test_labels)\n",
    "print(f\"Decision tree trained. Accuracy on training set: {100 * acc:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network.\n",
      "== Epoch 1/100 completed. Accuracy on test set: 0.06299006795608991\n",
      "== Epoch 2/100 completed. Accuracy on test set: 0.07344485101934135\n",
      "== Epoch 3/100 completed. Accuracy on test set: 0.08442237323575535\n",
      "== Epoch 4/100 completed. Accuracy on test set: 0.08860428646105593\n",
      "== Epoch 5/100 completed. Accuracy on test set: 0.20569785676947203\n",
      "== Epoch 6/100 completed. Accuracy on test set: 0.26659696811291167\n",
      "== Epoch 7/100 completed. Accuracy on test set: 0.3319393622582331\n",
      "== Epoch 8/100 completed. Accuracy on test set: 0.35258755880815473\n",
      "== Epoch 9/100 completed. Accuracy on test set: 0.3732357553580763\n",
      "== Epoch 10/100 completed. Accuracy on test set: 0.571353894406691\n",
      "== Epoch 11/100 completed. Accuracy on test set: 0.5933089388395191\n",
      "== Epoch 12/100 completed. Accuracy on test set: 0.6074228959749085\n",
      "== Epoch 13/100 completed. Accuracy on test set: 0.623366440146367\n",
      "== Epoch 14/100 completed. Accuracy on test set: 0.650810245687402\n",
      "== Epoch 15/100 completed. Accuracy on test set: 0.6738107684265552\n",
      "== Epoch 16/100 completed. Accuracy on test set: 0.6811291165708312\n",
      "== Epoch 17/100 completed. Accuracy on test set: 0.6897543125980136\n",
      "== Epoch 18/100 completed. Accuracy on test set: 0.7017773131207528\n",
      "== Epoch 19/100 completed. Accuracy on test set: 0.7062205959226346\n",
      "== Epoch 20/100 completed. Accuracy on test set: 0.7151071615263983\n",
      "== Epoch 21/100 completed. Accuracy on test set: 0.7216414009409304\n",
      "== Epoch 22/100 completed. Accuracy on test set: 0.7229482488238369\n",
      "== Epoch 23/100 completed. Accuracy on test set: 0.7239937271301621\n",
      "== Epoch 24/100 completed. Accuracy on test set: 0.7224255096706743\n",
      "== Epoch 25/100 completed. Accuracy on test set: 0.7302665969681129\n",
      "== Epoch 26/100 completed. Accuracy on test set: 0.7271301620491375\n",
      "== Epoch 27/100 completed. Accuracy on test set: 0.7279142707788814\n",
      "== Epoch 28/100 completed. Accuracy on test set: 0.7297438578149503\n",
      "== Epoch 29/100 completed. Accuracy on test set: 0.7320961840041819\n",
      "== Epoch 30/100 completed. Accuracy on test set: 0.7341871406168322\n",
      "== Epoch 31/100 completed. Accuracy on test set: 0.7326189231573444\n",
      "== Epoch 32/100 completed. Accuracy on test set: 0.7373235755358076\n",
      "== Epoch 33/100 completed. Accuracy on test set: 0.7417668583376895\n",
      "== Epoch 34/100 completed. Accuracy on test set: 0.7438578149503398\n",
      "== Epoch 35/100 completed. Accuracy on test set: 0.7503920543648719\n",
      "== Epoch 36/100 completed. Accuracy on test set: 0.7550967067433351\n",
      "== Epoch 37/100 completed. Accuracy on test set: 0.7710402509147936\n",
      "== Epoch 38/100 completed. Accuracy on test set: 0.7846314688970204\n",
      "== Epoch 39/100 completed. Accuracy on test set: 0.8092002090956613\n",
      "== Epoch 40/100 completed. Accuracy on test set: 0.8274960794563513\n",
      "== Epoch 41/100 completed. Accuracy on test set: 0.8470987976999478\n",
      "== Epoch 42/100 completed. Accuracy on test set: 0.8651332984840564\n",
      "== Epoch 43/100 completed. Accuracy on test set: 0.871144798745426\n",
      "== Epoch 44/100 completed. Accuracy on test set: 0.8792472556194459\n",
      "== Epoch 45/100 completed. Accuracy on test set: 0.8860428646105594\n",
      "== Epoch 46/100 completed. Accuracy on test set: 0.8873497124934657\n",
      "== Epoch 47/100 completed. Accuracy on test set: 0.8923157344485102\n",
      "== Epoch 48/100 completed. Accuracy on test set: 0.8972817564035547\n",
      "== Epoch 49/100 completed. Accuracy on test set: 0.8998954521693675\n",
      "== Epoch 50/100 completed. Accuracy on test set: 0.9012023000522739\n",
      "== Epoch 51/100 completed. Accuracy on test set: 0.9040773653946681\n",
      "== Epoch 52/100 completed. Accuracy on test set: 0.9074751698902248\n",
      "== Epoch 53/100 completed. Accuracy on test set: 0.9108729743857815\n",
      "== Epoch 54/100 completed. Accuracy on test set: 0.9171458442237324\n",
      "== Epoch 55/100 completed. Accuracy on test set: 0.9278619968635651\n",
      "== Epoch 56/100 completed. Accuracy on test set: 0.9315211709357031\n",
      "== Epoch 57/100 completed. Accuracy on test set: 0.932305279665447\n",
      "== Epoch 58/100 completed. Accuracy on test set: 0.9351803450078411\n",
      "== Epoch 59/100 completed. Accuracy on test set: 0.9357030841610037\n",
      "== Epoch 60/100 completed. Accuracy on test set: 0.9385781495033978\n",
      "== Epoch 61/100 completed. Accuracy on test set: 0.939623627809723\n",
      "== Epoch 62/100 completed. Accuracy on test set: 0.9419759539989545\n",
      "== Epoch 63/100 completed. Accuracy on test set: 0.9424986931521171\n",
      "== Epoch 64/100 completed. Accuracy on test set: 0.9438055410350236\n",
      "== Epoch 65/100 completed. Accuracy on test set: 0.9466806063774177\n",
      "== Epoch 66/100 completed. Accuracy on test set: 0.9490329325666492\n",
      "== Epoch 67/100 completed. Accuracy on test set: 0.9513852587558809\n",
      "== Epoch 68/100 completed. Accuracy on test set: 0.951646628332462\n",
      "== Epoch 69/100 completed. Accuracy on test set: 0.9524307370622059\n",
      "== Epoch 70/100 completed. Accuracy on test set: 0.9524307370622059\n",
      "== Epoch 71/100 completed. Accuracy on test set: 0.9532148457919498\n",
      "== Epoch 72/100 completed. Accuracy on test set: 0.9537375849451124\n",
      "== Epoch 73/100 completed. Accuracy on test set: 0.954260324098275\n",
      "== Epoch 74/100 completed. Accuracy on test set: 0.954260324098275\n",
      "== Epoch 75/100 completed. Accuracy on test set: 0.9545216936748563\n",
      "== Epoch 76/100 completed. Accuracy on test set: 0.9568740198640878\n",
      "== Epoch 77/100 completed. Accuracy on test set: 0.9573967590172504\n",
      "== Epoch 78/100 completed. Accuracy on test set: 0.9587036069001568\n",
      "== Epoch 79/100 completed. Accuracy on test set: 0.9592263460533194\n",
      "== Epoch 80/100 completed. Accuracy on test set: 0.9605331939362258\n",
      "== Epoch 81/100 completed. Accuracy on test set: 0.9605331939362258\n",
      "== Epoch 82/100 completed. Accuracy on test set: 0.9605331939362258\n",
      "== Epoch 83/100 completed. Accuracy on test set: 0.9605331939362258\n",
      "== Epoch 84/100 completed. Accuracy on test set: 0.9607945635128071\n",
      "== Epoch 85/100 completed. Accuracy on test set: 0.9610559330893884\n",
      "== Epoch 86/100 completed. Accuracy on test set: 0.9623627809722948\n",
      "== Epoch 87/100 completed. Accuracy on test set: 0.9623627809722948\n",
      "== Epoch 88/100 completed. Accuracy on test set: 0.9623627809722948\n",
      "== Epoch 89/100 completed. Accuracy on test set: 0.9631468897020387\n",
      "== Epoch 90/100 completed. Accuracy on test set: 0.9641923680083638\n",
      "== Epoch 91/100 completed. Accuracy on test set: 0.9639309984317825\n",
      "== Epoch 92/100 completed. Accuracy on test set: 0.9636696288552012\n",
      "== Epoch 93/100 completed. Accuracy on test set: 0.9639309984317825\n",
      "== Epoch 94/100 completed. Accuracy on test set: 0.9641923680083638\n",
      "== Epoch 95/100 completed. Accuracy on test set: 0.9641923680083638\n",
      "== Epoch 96/100 completed. Accuracy on test set: 0.9639309984317825\n",
      "== Epoch 97/100 completed. Accuracy on test set: 0.9644537375849451\n",
      "== Epoch 98/100 completed. Accuracy on test set: 0.9647151071615264\n",
      "== Epoch 99/100 completed. Accuracy on test set: 0.9644537375849451\n",
      "== Epoch 100/100 completed. Accuracy on test set: 0.9644537375849451\n"
     ]
    }
   ],
   "source": [
    "neural_network_c = NeuralNetworkClassifier(vectorizer, tfidf, hidden_size=1024)\n",
    "optimizer = torch.optim.Adam(neural_network_c.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "\n",
    "print(\"Training neural network.\")\n",
    "for e in range(1, epochs+1):\n",
    "    train_nn(network=neural_network_c, data=training_data, labels=training_labels, optimizer=optimizer)\n",
    "    acc, _ = test_nn(neural_network_c, test_data, test_labels)\n",
    "    print(f\"== Epoch {e}/{epochs} completed. Accuracy on test set: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive part\n",
    "Here the user can choose a classifier and then keep entering prompts for it *forever*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: anyhing else\n",
      "Predicted label: reqalts\n",
      "Prompt: other restaurants?\n",
      "Predicted label: reqalts\n",
      "Prompt: any other restaurants\n",
      "Predicted label: reqalts\n",
      "Prompt: yes\n",
      "Predicted label: affirm\n",
      "Prompt: no\n",
      "Predicted label: negate\n",
      "Prompt: exit\n"
     ]
    }
   ],
   "source": [
    "# Set your classifier here.\n",
    "CLF = neural_network_c\n",
    "\n",
    "def handle_input(s: str) -> None:\n",
    "    s = s.lower()\n",
    "    # Special case needed for the neural network.\n",
    "    if isinstance(CLF, Module):\n",
    "        with torch.no_grad():\n",
    "            out = CLF([s])\n",
    "        out = torch.argmax(out, dim=1)\n",
    "    else:\n",
    "        out = CLF([s])\n",
    "    return LABELS[out.item()]\n",
    "\n",
    "while True:\n",
    "    s = input(\"Prompt: \")\n",
    "    if s == \"exit\":\n",
    "        break\n",
    "    print(f\"Predicted label: {handle_input(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CLF, \"ckpt.pyt\")\n",
    "import pickle\n",
    "with open(\"preprocessing.utils\", 'wb') as file:\n",
    "    pickle.dump((vectorizer, tfidf), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lola",
   "language": "python",
   "name": "lola"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
